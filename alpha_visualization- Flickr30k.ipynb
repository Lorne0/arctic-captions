{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualizing the model  \n",
    "This notebook is meant as an example for how to create visualizations\n",
    "like the ones provided in the appendix.\n",
    "\n",
    "It is expected that this might need some slight modification depending on the user's \n",
    "setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "import numpy\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import capgen\n",
    "import generate_caps as gencaps\n",
    "import flickr8k\n",
    "import flickr30k\n",
    "import coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = {'flickr8k': (flickr8k.load_data, flickr8k.prepare_data),\n",
    "             'flickr30k': (flickr30k.load_data, flickr30k.prepare_data),\n",
    "             'coco': (coco.load_data, coco.prepare_data)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: flickr30k\n"
     ]
    }
   ],
   "source": [
    "# location of the model file, the pkl file should be named \"model_name.npz.pkl\"\n",
    "model= 'flickr30k_deterministic_model.npz'\n",
    "# location of the devset split file like the ones in /splits\n",
    "dev_list = './data/flickr30k/imageList.txt' \n",
    "image_path = './data/flickr30k/flickr30k-images/'\n",
    "\n",
    "\n",
    "# load model model_options\n",
    "with open('%s.pkl'%model, 'rb') as f:\n",
    "    options = pkl.load(f)\n",
    "\n",
    "print 'Loading: ' + options['dataset']\n",
    "\n",
    "flist = []\n",
    "with open(dev_list, 'r') as f:\n",
    "    for l in f:\n",
    "        flist.append(l.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep aspect ratio, and center crop\n",
    "def LoadImage(file_name, resize=256, crop=224):\n",
    "  image = Image.open(file_name)\n",
    "  width, height = image.size\n",
    "\n",
    "  if width > height:\n",
    "    width = (width * resize) / height\n",
    "    height = resize\n",
    "  else:\n",
    "    height = (height * resize) / width\n",
    "    width = resize\n",
    "  left = (width  - crop) / 2\n",
    "  top  = (height - crop) / 2\n",
    "  image_resized = image.resize((width, height), Image.BICUBIC).crop((left, top, left + crop, top + crop))\n",
    "  data = numpy.array(image_resized.convert('RGB').getdata()).reshape(crop, crop, 3)\n",
    "  data = data.astype('float32') / 255\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "    load_data, prepare_data = datasets[options['dataset']]\n",
    "\n",
    "    train, valid, test, worddict = load_data(False, True, False)\n",
    "    print 'Data loaded'\n",
    "\n",
    "    word_idict = dict()\n",
    "    for kk, vv in worddict.iteritems():\n",
    "        word_idict[vv] = kk\n",
    "    word_idict[0] = '<eos>'\n",
    "    word_idict[1] = 'UNK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Theano Graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building f_init... Done\n"
     ]
    }
   ],
   "source": [
    "    # build the sampling functions and model\n",
    "    trng = RandomStreams(1234)\n",
    "    use_noise = theano.shared(numpy.float32(0.), name='use_noise')\n",
    "\n",
    "    params = capgen.init_params(options)\n",
    "    params = capgen.load_params(model, params)\n",
    "    tparams = capgen.init_tparams(params)\n",
    "\n",
    "    # word index\n",
    "    f_init, f_next = capgen.build_sampler(tparams, options, use_noise, trng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    trng, use_noise, \\\n",
    "          inps, alphas, alphas_samples, \\\n",
    "          cost, opt_outs = \\\n",
    "          capgen.build_model(tparams, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the alphas and selector value [called \\beta in the paper]\n",
    "\n",
    "# create update rules for the stochastic attention\n",
    "hard_attn_updates = []\n",
    "if options['attn_type'] == 'stochastic':\n",
    "    baseline_time = theano.shared(numpy.float32(0.), name='baseline_time')\n",
    "    hard_attn_updates += [(baseline_time, baseline_time * 0.9 + 0.1 * opt_outs['masked_cost'].mean())]\n",
    "    hard_attn_updates += opt_outs['attn_updates']\n",
    "    \n",
    "f_alpha = theano.function(inps, alphas, name='f_alpha', updates=hard_attn_updates)\n",
    "if options['selector']:\n",
    "    f_sels = theano.function(inps, opt_outs['selector'], name='f_sels', updates=hard_attn_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Caption and Attention Visualization\n",
    "\n",
    "(The next five cells can be run over and over to visualize a random image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "idx = numpy.random.randint(0, len(valid[0])) # random image\n",
    "k = 1 # beam width\n",
    "use_gt = False # set to False if you want to use the generated sample\n",
    "gt = valid[0][idx][0] # groundtruth\n",
    "context = numpy.array(valid[1][valid[0][idx][1]].todense()).reshape([14*14, 512]).astype('float32') # annotations\n",
    "print type(context[0][0])\n",
    "img = LoadImage(image_path+flist[valid[0][idx][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not use_gt:\n",
    "    \n",
    "    sample, score = capgen.gen_sample(tparams, f_init, f_next, context, \n",
    "                                      options, trng=trng, k=k, maxlen=200, stochastic=False)\n",
    "    sidx = numpy.argmin(score)\n",
    "    caption = sample[sidx][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "GT: A man and woman walking down the street .\n"
     ]
    }
   ],
   "source": [
    "# print the generated caption and the ground truth\n",
    "if use_gt:\n",
    "    caption = map(lambda w: worddict[w] if worddict[w] < options['n_words'] else 1, gt.split())\n",
    "words = map(lambda w: word_idict[w] if w in word_idict else '<UNK>', caption)\n",
    "print 'Sample:', ' '.join(words)\n",
    "print 'GT:', gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = f_alpha(numpy.array(caption).reshape(len(caption),1), \n",
    "                numpy.ones((len(caption),1), dtype='float32'), \n",
    "                context.reshape(1,context.shape[0],context.shape[1]))\n",
    "if options['selector']:\n",
    "    sels = f_sels(numpy.array(caption).reshape(len(caption),1), \n",
    "                   numpy.ones((len(caption),1), dtype='float32'), \n",
    "                   context.reshape(1,context.shape[0],context.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Visualization   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEFCAYAAACsDJN+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxR6T7yq1fAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70de07b3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the visualization\n",
    "n_words = alpha.shape[0] + 1\n",
    "w = numpy.round(numpy.sqrt(n_words))\n",
    "h = numpy.ceil(numpy.float32(n_words) / w)\n",
    "        \n",
    "plt.subplot(w, h, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "smooth = True\n",
    "\n",
    "for ii in xrange(alpha.shape[0]):\n",
    "    plt.subplot(w, h, ii+2)\n",
    "    lab = words[ii]\n",
    "    if options['selector']:\n",
    "        lab += '(%0.2f)'%sels[ii]\n",
    "    plt.text(0, 1, lab, backgroundcolor='white', fontsize=13)\n",
    "    plt.text(0, 1, lab, color='black', fontsize=13)\n",
    "    plt.imshow(img)\n",
    "    if smooth:\n",
    "        alpha_img = skimage.transform.pyramid_expand(alpha[ii,0,:].reshape(14,14), upscale=16, sigma=20)\n",
    "    else:\n",
    "        alpha_img = skimage.transform.resize(alpha[ii,0,:].reshape(14,14), [img.shape[0], img.shape[1]])\n",
    "    plt.imshow(alpha_img, alpha=0.8)\n",
    "    plt.set_cmap(cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
